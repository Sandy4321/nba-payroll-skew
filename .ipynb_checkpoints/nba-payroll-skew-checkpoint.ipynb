{
 "metadata": {
  "name": "",
  "signature": "sha256:cd7897a2826742e79f0e781ccddb3855b4de7e536440a7e8b8d0582ff80d00d0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NBA Payroll Skewness\n",
      "====================\n",
      "*Analyzing the role of skewness in an NBA team's payroll in team performance*\n",
      "\n",
      "Introduction\n",
      "------------\n",
      "The NBA is known for having a complex salary system, with all sorts of restrictions and caps.  Moreover, star players often make waves as they sign multi-year, multi-million dollar contracts.  The following is a straightforward exercise that uses the `BeautifulSoup` Python package to scrape NBA payroll data from the web and apply analysis with respect to team performance.  \n",
      "  \n",
      "Teams\n",
      "----\n",
      "We will treat the payroll of a given team in a given year as one data point.  Although we could simply hardcode in the names of the NBA teams (go Warriors), we prefer to explore `bs4` a little bit.  To get the upcoming season's team names, we go to [ESPN's NBA Teams page](http://espn.go.com/nba/teams).  In order to leverage Beautiful Soup, we have to inspect the HTML of the page and see if there is a specific pattern for each div that contains a team name.  After doing so, we write the `is_team` method that checks BS tags, and make the request:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def is_team(tag):\n",
      "    return tag.has_attr('class') and tag.name == 'a' and ('bi' in tag['class'])\n",
      "\n",
      "url = 'http://espn.go.com/nba/teams'\n",
      "r = requests.get(url)\n",
      "soup = BeautifulSoup(r.text)\n",
      "teams = [team_tag.string for team_tag in soup.find_all(is_team)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print teams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'Boston Celtics', u'Brooklyn Nets', u'New York Knicks', u'Philadelphia 76ers', u'Toronto Raptors', u'Golden State Warriors', u'Los Angeles Clippers', u'Los Angeles Lakers', u'Phoenix Suns', u'Sacramento Kings', u'Chicago Bulls', u'Cleveland Cavaliers', u'Detroit Pistons', u'Indiana Pacers', u'Milwaukee Bucks', u'Dallas Mavericks', u'Houston Rockets', u'Memphis Grizzlies', u'New Orleans Pelicans', u'San Antonio Spurs', u'Atlanta Hawks', u'Charlotte Hornets', u'Miami Heat', u'Orlando Magic', u'Washington Wizards', u'Denver Nuggets', u'Minnesota Timberwolves', u'Oklahoma City Thunder', u'Portland Trail Blazers', u'Utah Jazz']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can move to collect the payroll data for each team and for a range of years.  It appears that [Shamsports Data](data.shamsports.com) has the best collection that is publicly and freely available.  After exploring the website a bit, we hypothesize that a given team and year's payroll is available in the following URL format:  \n",
      "\"http://data.shamsports.com/content/pages/data/salaries/\" + year + \"/\" + team name + \".jsp\"  \n",
      "  \n",
      "For example, the 2012 Warriors (season = 2011-2012) payroll data is most easily accessible at \"http://data.shamsports.com/content/pages/data/salaries/2012/warriors.jsp\".  If you follow the link, you'll notice that that page also gives information for the 2012-2013 season, and the 2013-2014 season (though incomplete).  This is because the site attempts to project the payroll for future years given the then-current contracts.  To get the most accurate data, we'll want to use the `requests` package to get make separate requests for each data point.  \n",
      "  \n",
      "Let's check if our URL schema is right, and just how much data is available to us.  We do so with a 2d Numpy array of 0's and 1's, indicating failed and successful requests, respectively:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "base = 'http://data.shamsports.com/content/pages/data/salaries/'\n",
      "years = range(2000, 2015)\n",
      "x = np.ones((len(teams), len(years)), dtype=np.int)\n",
      "test_url = [t.split()[-1].lower() for t in teams]\n",
      "\n",
      "# if one of our rows is all 0s, that means the team url is actually wrong\n",
      "i = 0\n",
      "for tu in test_url:\n",
      "    j = 0\n",
      "    for year in years:\n",
      "        url = base + str(year) + '/' + tu + '.jsp'\n",
      "        r = requests.get(url)\n",
      "        if r.status_code == 404:\n",
      "            x[i, j] = 0 # mark it as a failed request\n",
      "            # print '404 for team \"' + tu + '\" and year ' + str(year)\n",
      "        j += 1\n",
      "    i += 1\n",
      "\n",
      "df = pd.DataFrame(x, index=test_url, columns=years)\n",
      "print df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              2000  2001  2002  2003  2004  2005  2006  2007  2008  2009  \\\n",
        "celtics          0     0     0     0     0     0     0     1     1     1   \n",
        "nets             0     0     0     0     0     0     0     1     1     1   \n",
        "knicks           0     0     0     0     0     0     0     1     1     1   \n",
        "76ers            0     0     0     0     0     0     0     0     0     0   \n",
        "raptors          0     0     0     0     0     0     0     1     1     1   \n",
        "warriors         0     0     0     0     0     0     0     1     1     1   \n",
        "clippers         0     0     0     0     0     0     0     1     1     1   \n",
        "lakers           0     0     0     0     0     0     0     1     1     1   \n",
        "suns             0     0     0     0     0     0     0     1     1     1   \n",
        "kings            0     0     0     0     0     0     0     1     1     1   \n",
        "bulls            0     0     0     0     0     0     0     1     1     1   \n",
        "cavaliers        0     0     0     0     0     0     0     1     1     1   \n",
        "pistons          0     0     0     0     0     0     0     1     1     1   \n",
        "pacers           0     0     0     0     0     0     0     1     1     1   \n",
        "bucks            0     0     0     0     0     0     0     1     1     1   \n",
        "mavericks        0     0     0     0     0     0     0     1     1     1   \n",
        "rockets          0     0     0     0     0     0     0     1     1     1   \n",
        "grizzlies        0     0     0     0     0     0     0     1     1     1   \n",
        "pelicans         0     0     0     0     0     0     0     0     0     0   \n",
        "spurs            0     0     0     0     0     0     0     1     1     1   \n",
        "hawks            0     0     0     0     0     0     0     1     1     1   \n",
        "hornets          0     0     0     0     0     0     0     1     1     1   \n",
        "heat             0     0     0     0     0     0     0     1     1     1   \n",
        "magic            0     0     0     0     0     0     0     1     1     1   \n",
        "wizards          0     0     0     0     0     0     0     1     1     1   \n",
        "nuggets          0     0     0     0     0     0     0     1     1     1   \n",
        "timberwolves     0     0     0     0     0     0     0     1     1     1   \n",
        "thunder          0     0     0     0     0     0     0     0     0     1   \n",
        "blazers          0     0     0     0     0     0     0     1     1     1   \n",
        "jazz             0     0     0     0     0     0     0     1     1     1   \n",
        "\n",
        "              2010  2011  2012  2013  2014  \n",
        "celtics          1     1     1     1     1  \n",
        "nets             1     1     1     1     1  \n",
        "knicks           1     1     1     1     1  \n",
        "76ers            0     0     0     0     0  \n",
        "raptors          1     1     1     1     1  \n",
        "warriors         1     1     1     1     1  \n",
        "clippers         1     1     1     1     1  \n",
        "lakers           1     1     1     1     1  \n",
        "suns             1     1     1     1     1  \n",
        "kings            1     1     1     1     1  \n",
        "bulls            1     1     1     1     1  \n",
        "cavaliers        1     1     1     1     1  \n",
        "pistons          1     1     1     1     1  \n",
        "pacers           1     1     1     1     1  \n",
        "bucks            1     1     1     1     1  \n",
        "mavericks        1     1     1     1     1  \n",
        "rockets          1     1     1     1     1  \n",
        "grizzlies        1     1     1     1     1  \n",
        "pelicans         0     0     0     1     1  \n",
        "spurs            1     1     1     1     1  \n",
        "hawks            1     1     1     1     1  \n",
        "hornets          1     1     1     0     1  \n",
        "heat             1     1     1     1     1  \n",
        "magic            1     1     1     1     1  \n",
        "wizards          1     1     1     1     1  \n",
        "nuggets          1     1     1     1     1  \n",
        "timberwolves     1     1     1     1     1  \n",
        "thunder          1     1     1     1     1  \n",
        "blazers          1     1     1     1     1  \n",
        "jazz             1     1     1     1     1  \n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we check which rows are all 0 (which URL's are completely incorrect), we find the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print df[(df.T == 0).all()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       2000  2001  2002  2003  2004  2005  2006  2007  2008  2009  2010  2011  \\\n",
        "76ers     0     0     0     0     0     0     0     0     0     0     0     0   \n",
        "\n",
        "       2012  2013  2014  \n",
        "76ers     0     0     0  \n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks like 76ers is just wrong (404 for all years attempted), so let's try the URL 'sixers'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tu = u'sixers'\n",
      "i = 3 ## << index of the sixers\n",
      "j = 0\n",
      "for year in years:\n",
      "    url = base + str(year) + '/' + tu + '.jsp'\n",
      "    r = requests.get(url)\n",
      "    if r.status_code != 404:\n",
      "        x[i, j] = 1 # score (jk Sixers don't know how to do that)\n",
      "        # print 'URL valid for team \"' + tu + '\" and year ' + str(year)\n",
      "    j += 1\n",
      "\n",
      "test_url[3] = tu\n",
      "df = pd.DataFrame(x, index=test_url, columns=years)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we can look at which columns are all zero, which can let us know the earliest season that the website has data for:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print df.columns[(df == 0).all()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Int64Index([2000, 2001, 2002, 2003, 2004, 2005, 2006], dtype='int64')\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the earliest season is 2007, then, we slice our Pandas DataFrame and `pickle` it for further usage:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.loc[:, ~(df == 0).all()]\n",
      "\n",
      "import pickle\n",
      "pickle.dump(df, open('valid_pages.p', 'wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We also note that there are 0s for valid URL's past 2007 -- this is due to the unfortunate franchise relocations and renamings (New Orleans Hornets became the New Orleans Pelicans, etc.).  We'll proceed with our data frame of valid pages, scrape the salaries, and fill in the non-standard holes afterwards."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Salaries\n",
      "--------\n",
      "Now that we have our valid pages, we begin the iterative process of scraping the actual salary numbers from each valid page.  We simply leave here the final result (which includes hard-coding some teams where the HTML is just too messy.  Honestly, what can you do when the website is designed by someone who includes \"$19,000,000ish\" as a data point, or decides to randomly not add a new tr tag but still count it as a row?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_salary_table(tag):\n",
      "    return tag.name == 'table' and (tag.tr is not None) and \\\n",
      "    (all([(t.has_attr('class') and t['class'][0] == 'blue4') for \n",
      "        t in tag.tr.findAll('td')]))\n",
      "def is_total_row(tag):\n",
      "    return tag.name == 'tr' and (tag.td is not None) and (tag.td.string is not None) \\\n",
      "    and (re.sub(':', '', ''.join(tag.td.string.split()).lower()) == 'totalsalaries') \n",
      "    # classic \"Total salaries\" vs \"Total Salaries\" vs \"Total Salaries:\"\n",
      "def is_player_row(tag):\n",
      "    return tag.name == 'tr' and (tag.td is not None) and (tag.td.find('a') is not None) and \\\n",
      "    (len(tag.findAll('td')) >= 6)\n",
      "def float_conv(s):\n",
      "    if len(s) == 0:\n",
      "        return 0.\n",
      "    return float(s)\n",
      "\n",
      "# given the url to the shamsports.com site\n",
      "def extractSalaryPercents(url):\n",
      "    r = requests.get(url)\n",
      "    soup = BeautifulSoup(r.text)\n",
      "    if url == 'http://data.shamsports.com/content/pages/data/salaries/2008/mavericks.jsp':\n",
      "        tot = 106948621.\n",
      "    elif url == 'http://data.shamsports.com/content/pages/data/salaries/2007/jazz.jsp':\n",
      "        tot = 61310247.\n",
      "    else:\n",
      "        total_row = soup.find(is_total_row)\n",
      "        totals = [float(re.sub(',', '', t.string[1:])) for t in total_row.findAll('b')[1:] if (t.string is not None)]\n",
      "        tot = totals[0]\n",
      "\n",
      "    sal_table = soup.findAll(is_salary_table)[0]\n",
      "    player_rows = sal_table.findAll(is_player_row)\n",
      "    sal_strings = [p.findAll('td')[1].string for p in player_rows]\n",
      "    sal_strings = [s for s in sal_strings if s != 'N/A']\n",
      "    sal_strings = [re.sub(r'[a-zA-Z]', '', s) for s in sal_strings]\n",
      "    sals = [float_conv(re.sub(',', '', re.sub('\\$', '', s))) for s in sal_strings]\n",
      "    sal_percs = [sal / tot for sal in sals]\n",
      "    return sal_percs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're going to track the salary in another Pandas DataFrame -- the number of columns is 42 simply because we want to allow for strange circumstances where teams are paying more than ~12 players.  We omit the output from the code below because, as explained above, it was an iterative process that resulted in many adjustments to the functions defined above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pickle.load(open('valid_pages.p', 'rb'))\n",
      "base = 'http://data.shamsports.com/content/pages/data/salaries/'\n",
      "###################\n",
      "# columns: team | year | player 1 salary percentage | player 2 salary percentage ...\n",
      "ncol = 42\n",
      "sal_perc_df = pd.DataFrame(np.ones((df.values[df.values == 1].size, ncol), dtype=np.float64), \n",
      "                           columns=['team', 'year'] + ['p' + str(i) for i in range(1,41)])\n",
      "rc = 0\n",
      "\n",
      "# fill the salary df\n",
      "scrape_bad = False\n",
      "for i in range(0, df.shape[0]):\n",
      "    for j in range(0, df.shape[1]):\n",
      "        if df.iloc[i, j] == 1:\n",
      "            sal_perc_df['team'][rc] = df.index[i]\n",
      "            sal_perc_df['year'][rc] = df.columns[j]\n",
      "            # scrape salary data\n",
      "            url = base + str(df.columns[j]) + '/' + df.index[i] + '.jsp'\n",
      "            try:\n",
      "                sal_percs = cs.extractSalaryPercents(url)\n",
      "            except:\n",
      "                print 'Scraping error on url <' + url + '>'\n",
      "                print 'Improve your extract function, you noob.'\n",
      "                scrape_bad = True\n",
      "                break\n",
      "            sal_percs += [0] * ((ncol - 2) - len(sal_percs)) \n",
      "            # pad the zeros\n",
      "            sal_perc_df.iloc[rc, 2:] = sal_percs # fill that row in         \n",
      "            rc += 1\n",
      "            print 'Finished payroll for ' + df.index[i] + ', ' + str(df.columns[j])\n",
      "        else:\n",
      "            print 'Skipping 404 page'\n",
      "    if scrape_bad:\n",
      "        break   \n",
      "\n",
      "pickle.dump(sal_perc_df, open('payroll_shamsports.p', 'wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filling in the Holes\n",
      "--------------------\n",
      "Our salary data frame is looking pretty good:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sal_perc_df = pickle.load(open('payroll_shamsports.p', 'rb'))\n",
      "print sal_perc_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      team  year        p1        p2        p3        p4        p5        p6  \\\n",
        "0  celtics  2007  0.241152  0.188031  0.186301  0.083729  0.044602  0.033398   \n",
        "1  celtics  2008  0.319724  0.220223  0.215375  0.060317  0.043156  0.040383   \n",
        "2  celtics  2009  0.312568  0.232209  0.228288  0.057822  0.040497  0.033464   \n",
        "3  celtics  2010  0.233356  0.221346  0.193528  0.069008  0.058941  0.053047   \n",
        "4  celtics  2011  0.247299  0.182222  0.131318  0.119380  0.075705  0.072791   \n",
        "\n",
        "         p7        p8    ...     p31  p32  p33  p34  p35  p36  p37  p38  p39  \\\n",
        "0  0.030961  0.028634    ...       0    0    0    0    0    0    0    0    0   \n",
        "1  0.025147  0.020191    ...       0    0    0    0    0    0    0    0    0   \n",
        "2  0.031570  0.016607    ...       0    0    0    0    0    0    0    0    0   \n",
        "3  0.040243  0.035365    ...       0    0    0    0    0    0    0    0    0   \n",
        "4  0.058515  0.039396    ...       0    0    0    0    0    0    0    0    0   \n",
        "\n",
        "   p40  \n",
        "0    0  \n",
        "1    0  \n",
        "2    0  \n",
        "3    0  \n",
        "4    0  \n",
        "\n",
        "[5 rows x 42 columns]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "but again, there are holes in the rows where we had \"invalid\" pages in our ShamSports URL testing.  What we really want is to rename all the teams by their city and year (so we don't run into problems with Charlotte Hornets vs. Charlotte Bobcats vs. New Orleans Hornets), and then individually scrape the missing data.  We do so with the following code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from the team history page for each of those team names (team names)\n",
      "# for the upcoming \"2015\" season, we have\n",
      "#\n",
      "# hornets: \n",
      "# 2015 - present    NBA     Charlotte Hornets\n",
      "# 2005 - 2014       NBA     Charlotte Bobcats\n",
      "# 1989 - 2002       NBA     Charlotte Hornets\n",
      "# \n",
      "# pelicans:\n",
      "# 2014 - present    NBA     New Orleans Pelicans\n",
      "# 2007 - 2013       NBA     New Orleans Hornets\n",
      "# 2006 - 2007       NBA     New Orleans/Oklahoma City Hornets\n",
      "# 2003 - 2006       NBA     New Orleans Hornets\n",
      "#\n",
      "# thunder:\n",
      "# 2009 - present    NBA     Oklahoma City Thunder\n",
      "# 1968 - 2008       NBA     Seattle Supersonics\n",
      "\n",
      "# this means that we need to retrieve the following salary data to make \n",
      "# our data frame 30 (number of teams) * 8 (number of seasons we have) \n",
      "# = 240 rows, and also label the team names as 'Charlotte Hornets'\n",
      "# instead of just 'hornets' so our data frame will look more like:\n",
      "# new_york_knicks         2007    x0\n",
      "# new_orleans_pelicans    2014    x1\n",
      "# new_orleans_hornets     2013    x2, etc.\n",
      "\n",
      "# names of current teams\n",
      "teams = ['_'.join(t.lower().split()) for t in get_teams.retrieve()]\n",
      "\n",
      "ncol = 42\n",
      "sal_perc_df_full = pd.DataFrame(np.ones((240, ncol), \n",
      "    dtype=np.float64), columns=['team', 'year'] + ['p' + str(i) for i in range(1,ncol - 1)]) \n",
      "\n",
      "num_seasons = 8 # 2007 - 2014\n",
      "old_count = 0 # tracks where we are in sal_perc_df\n",
      "for i in range(0, len(teams)):\n",
      "\n",
      "    inds = range((i * num_seasons),((i + 1) * num_seasons))\n",
      "\n",
      "    if sal_perc_df['team'][old_count] == 'hornets':\n",
      "        sal_perc_df_full['team'][inds] = u'charlotte_bobcats'\n",
      "        sal_perc_df_full['year'][inds] = range(2007, 2015)\n",
      "        old_count += sal_perc_df[sal_perc_df['team'] == 'hornets'].shape[0]\n",
      "\n",
      "    elif sal_perc_df['team'][old_count] == 'pelicans':\n",
      "        sal_perc_df_full['team'][inds[0:-1]] = u'new_orleans_hornets'\n",
      "        sal_perc_df_full['team'][inds[-1]] = u'new_orleans_pelicans'\n",
      "        sal_perc_df_full['year'][inds] = range(2007, 2015)\n",
      "        old_count += sal_perc_df[sal_perc_df['team'] == 'pelicans'].shape[0]\n",
      "    elif sal_perc_df['team'][old_count] == 'thunder':\n",
      "        sal_perc_df_full['team'][inds[0:2]] == u'seattle_supersonics'\n",
      "        sal_perc_df_full['team'][inds[2:]] == u'oklahoma_city_thunder'\n",
      "        sal_perc_df_full['year'][inds] = range(2007, 2015)\n",
      "        old_count += sal_perc_df[sal_perc_df['team'] == 'thunder'].shape[0]\n",
      "    else:\n",
      "        # name the team the right name\n",
      "        sal_perc_df_full['team'][inds] = teams[i]\n",
      "        sal_perc_df_full['year'][inds] = range(2007, 2015)\n",
      "        old_percs = sal_perc_df.iloc[old_count:old_count + num_seasons,\n",
      "            2:ncol]\n",
      "        sal_perc_df_full.iloc[inds, 2:ncol] = old_percs\n",
      "        old_count = old_count + num_seasons\n",
      "\n",
      "# now we need to fill in salary data for Charlotte Bobcats,\n",
      "# New Orleans Hornets/New Orleans Pelicans, Seattle Supersonics/\n",
      "# Oklahoma City Thunder\n",
      "\n",
      "# NO Hornets\n",
      "sal_perc_df_full.iloc[144:150, 2:] = sal_perc_df[sal_perc_df['team'] == 'hornets'].iloc[0:-1, 2:]\n",
      "# NO Pelicans\n",
      "sal_perc_df_full.iloc[150:152, 2:] = sal_perc_df[sal_perc_df['team'] == 'pelicans'].iloc[:, 2:]\n",
      "# OKC\n",
      "sal_perc_df_full.iloc[218:224, 2:] = sal_perc_df[sal_perc_df['team'] == 'thunder'].iloc[:, 2:]\n",
      "\n",
      "# now salaries that we haven't collected:\n",
      "# Supersonics data can't be found on ShamSports, so we're making it nan\n",
      "sal_perc_df_full.iloc[216:218, 2:] = float('nan')\n",
      "\n",
      "# Charlotte Bobcats (only changing to Charlotte Hornets for \n",
      "# 2014-2015 season)\n",
      "sal_perc_df_full.iloc[168:176, 0:3]\n",
      "\n",
      "i = 0\n",
      "for year in range(2007, 2015):\n",
      "    sal_percs = cs.extractSalaryPercents('http://data.shamsports.com/content/pages/data/salaries/' + str(year) + '/bobcats.jsp')\n",
      "    sal_percs += [0] * ((ncol - 2) - len(sal_percs))\n",
      "    sal_perc_df_full.iloc[168 + i, 2:] = sal_percs\n",
      "    i += 1\n",
      "\n",
      "pickle.dump(sal_perc_df_full, open('fixed_payroll_shamsports.p', 'wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}